#!/usr/bin/env python3
"""
å¿«é€Ÿå¼€å§‹è„šæœ¬
æ¼”ç¤ºCharacter OOC Detectorçš„åŸºæœ¬åŠŸèƒ½
"""

import os
import sys

# è·å–è„šæœ¬æ‰€åœ¨ç›®å½•çš„ç»å¯¹è·¯å¾„
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
# åˆ‡æ¢åˆ°é¡¹ç›®æ ¹ç›®å½•
os.chdir(SCRIPT_DIR)

def print_banner():
    """æ‰“å°æ¬¢è¿ä¿¡æ¯"""
    print("=" * 70)
    print("  Character OOC Detector - è§’è‰²äººæ ¼ä¸€è‡´æ€§æ£€æµ‹å™¨")
    print("  MVPç‰ˆæœ¬ - å¿«é€Ÿå¼€å§‹å‘å¯¼")
    print("=" * 70)
    print()
    print("ğŸ“Œ æ•°æ®ç”Ÿæˆç­–ç•¥:")
    print("  1. ä¼˜å…ˆå°è¯•ä½¿ç”¨OpenAI APIç”Ÿæˆé«˜è´¨é‡è®­ç»ƒæ•°æ®")
    print("  2. ç”Ÿæˆçš„æ•°æ®ä¼šç¼“å­˜åˆ° data/ ç›®å½•ï¼Œå¯é‡å¤ä½¿ç”¨")
    print("  3. å¦‚APIæœªé…ç½®ï¼Œè‡ªåŠ¨é™çº§ä½¿ç”¨fallbackæ¼”ç¤ºæ•°æ®")
    print("  4. fallbackæ•°æ®è´¨é‡è¾ƒä½ä½†è¶³å¤Ÿä½“éªŒå®Œæ•´æµç¨‹")
    print()
    print("ğŸ’¡ æç¤º: é…ç½®APIå¯è·å¾—æ›´å¥½çš„è®­ç»ƒæ•ˆæœ")
    print("   å‚è€ƒ: CONFIG_GUIDE.md æˆ– config/config.yaml.example")
    print()

def check_dependencies():
    """æ£€æŸ¥ä¾èµ–æ˜¯å¦å®‰è£…"""
    print("ğŸ“¦ æ£€æŸ¥ä¾èµ–...")
    
    required_packages = [
        "torch",
        "transformers",
        "datasets"
    ]
    
    missing = []
    for package in required_packages:
        try:
            __import__(package)
            print(f"  âœ“ {package}")
        except ImportError:
            missing.append(package)
            print(f"  âœ— {package} (æœªå®‰è£…)")
    
    if missing:
        print(f"\nâŒ ç¼ºå°‘ä¾èµ–: {', '.join(missing)}")
        print("è¯·è¿è¡Œ: pip install -r requirements.txt")
        return False
    
    print("âœ… æ‰€æœ‰ä¾èµ–å·²å®‰è£…\n")
    return True

def demo_persona():
    """æ¼”ç¤ºPersonaåŠŸèƒ½"""
    print("\n" + "=" * 70)
    print("ğŸ“‹ æ­¥éª¤ 1: é€‰æ‹©å¹¶åŠ è½½è§’è‰²äººè®¾")
    print("=" * 70)
    
    from src import Persona
    
    # åˆ—å‡ºå¯ç”¨çš„äººè®¾
    personas = {
        "1": {
            "name": "å¼ ä¸‰ - æ±Ÿæ¹–ä¾ å®¢",
            "path": "config/example_persona.json",
            "description": "å°‘æ—å¼Ÿå­ï¼Œé‡æƒ…é‡ä¹‰ï¼Œè¯´è¯ç®€æ´ç›´æ¥"
        },
        "2": {
            "name": "è‰¾è‰å¨… - çŒ«å¨˜å¥³ä»†",
            "path": "config/catgirl_maid_persona.json",
            "description": "ç»´å¤šåˆ©äºšæ—¶ä»£å¥³ä»†ï¼Œæ¸©æŸ”ç¤¼è²Œï¼Œå¸¦çŒ«ç³»å£ç™–"
        }
    }
    
    print("\nå¯é€‰è§’è‰²äººè®¾ï¼š")
    for key, info in personas.items():
        print(f"  {key}. {info['name']}")
        print(f"     {info['description']}")
    
    # ç”¨æˆ·é€‰æ‹©
    choice = input("\nè¯·é€‰æ‹©äººè®¾ (1/2ï¼Œé»˜è®¤1): ").strip() or "1"
    
    if choice not in personas:
        print(f"æ— æ•ˆé€‰æ‹©ï¼Œä½¿ç”¨é»˜è®¤äººè®¾")
        choice = "1"
    
    selected = personas[choice]
    persona_path = selected["path"]
    
    if not os.path.exists(persona_path):
        print(f"âŒ äººè®¾æ–‡ä»¶ä¸å­˜åœ¨: {persona_path}")
        return None, None
    
    persona = Persona.from_json(persona_path)
    print(f"\nâœ… æˆåŠŸåŠ è½½è§’è‰²: {selected['name']}")
    print(persona)
    
    # éªŒè¯å®Œæ•´æ€§
    is_valid = persona.validate()
    if is_valid:
        print("\nâœ“ äººè®¾éªŒè¯é€šè¿‡")
    
    return persona, choice

def demo_training(persona_choice="1"):
    """æ¼”ç¤ºè®­ç»ƒæµç¨‹"""
    print("\n" + "=" * 70)
    print("ğŸ”§ æ­¥éª¤ 2: å‡†å¤‡è®­ç»ƒæ•°æ®")
    print("=" * 70)
    
    from src import RMTrainer, PreferencePair, SampleGenerator, Persona
    from src.config_loader import get_config
    
    # ç¡®å®šæ•°æ®æ–‡ä»¶è·¯å¾„
    persona_names = {"1": "zhangsan", "2": "catgirl"}
    persona_paths = {"1": "config/example_persona.json", "2": "config/catgirl_maid_persona.json"}
    
    data_file = f"data/training_pairs_{persona_names[persona_choice]}.jsonl"
    
    # æ£€æŸ¥æ˜¯å¦å·²æœ‰ç¼“å­˜æ•°æ®
    if os.path.exists(data_file):
        existing_pairs = SampleGenerator.load_pairs_from_jsonl(data_file)
        print(f"\nâœ“ å‘ç°ç¼“å­˜æ•°æ®: {data_file} ({len(existing_pairs)} ä¸ªæ ·æœ¬)")
        
        print("\né€‰æ‹©æ“ä½œ:")
        print("  1. ä½¿ç”¨ç°æœ‰æ•°æ®")
        print("  2. è¿½åŠ æ–°æ•°æ®åˆ°ç°æœ‰æ–‡ä»¶")
        print("  3. é‡æ–°ç”Ÿæˆï¼ˆè¦†ç›–ï¼‰")
        
        choice = input("\nè¯·é€‰æ‹© (1/2/3ï¼Œé»˜è®¤1): ").strip() or "1"
        
        if choice == "1":
            print("ä½¿ç”¨ç°æœ‰æ•°æ®...")
            demo_pairs = existing_pairs
        elif choice == "2":
            print("è¿½åŠ æ¨¡å¼...")
            new_pairs = _generate_training_data(persona_choice, persona_paths, data_file, append_mode=True)
            if new_pairs:
                demo_pairs = existing_pairs + new_pairs
                print(f"âœ“ æ€»è®¡: {len(demo_pairs)} ä¸ªæ ·æœ¬ (åŸæœ‰{len(existing_pairs)} + æ–°å¢{len(new_pairs)})")
            else:
                demo_pairs = existing_pairs
        else:
            print("é‡æ–°ç”Ÿæˆæ¨¡å¼...")
            demo_pairs = _generate_training_data(persona_choice, persona_paths, data_file, append_mode=False)
    else:
        demo_pairs = _generate_training_data(persona_choice, persona_paths, data_file, append_mode=False)
    
    if not demo_pairs:
        print("âŒ æ— æ³•è·å–è®­ç»ƒæ•°æ®")
        return None
    
    # ç»§ç»­è®­ç»ƒæµç¨‹...
    _run_training(demo_pairs)
    
    return "./checkpoints/quick_start"


def _generate_training_data(persona_choice, persona_paths, data_file, append_mode=False):
    """ç”Ÿæˆæˆ–ä½¿ç”¨fallbackè®­ç»ƒæ•°æ®"""
    from src import SampleGenerator, Persona
    from src.config_loader import get_config
    
    print("\nå°è¯•ä½¿ç”¨LLMç”Ÿæˆè®­ç»ƒæ•°æ®...")
    
    # æ£€æŸ¥APIé…ç½®
    config = get_config()
    if config.check_api_configured():
        try:
            print("âœ“ OpenAI APIå·²é…ç½®ï¼Œç”Ÿæˆé«˜è´¨é‡è®­ç»ƒæ•°æ®...")
            persona = Persona.from_json(persona_paths[persona_choice])
            generator = SampleGenerator(persona)
            
            # ä»é…ç½®è¯»å–ç”Ÿæˆæ•°é‡
            sample_config = config.get_sample_generation_config()
            default_num = sample_config.get("num_pairs", 100)
            
            # è®¡ç®—èµ·å§‹ç´¢å¼•ï¼ˆè¿½åŠ æ¨¡å¼ä¸‹é¿å…indexé‡å¤ï¼‰
            start_index = 0
            if append_mode and os.path.exists(data_file):
                existing = SampleGenerator.load_pairs_from_jsonl(data_file)
                start_index = len(existing)
            
            # å¦‚æœæ˜¯è¿½åŠ æ¨¡å¼ï¼Œè¯¢é—®æ•°é‡
            if append_mode:
                print(f"\nå½“å‰é…ç½®é»˜è®¤ç”Ÿæˆ: {default_num} ä¸ªæ ·æœ¬")
                num_input = input(f"è¦ç”Ÿæˆå¤šå°‘ä¸ªæ–°æ ·æœ¬ï¼Ÿ(é»˜è®¤{default_num}): ").strip()
                num_pairs = int(num_input) if num_input else default_num
            else:
                num_pairs = default_num
                print(f"ç”Ÿæˆ {num_pairs} ä¸ªåå¥½å¯¹...")
            
            # ç”Ÿæˆåå¥½å¯¹ï¼ˆä½¿ç”¨æ­£ç¡®çš„èµ·å§‹ç´¢å¼•ï¼‰
            demo_pairs = generator.generate_preference_pairs(
                num_pairs=num_pairs,
                start_index=start_index
            )
            
            # ä¿å­˜åˆ°æ–‡ä»¶
            os.makedirs("data", exist_ok=True)
            
            if append_mode:
                # è¿½åŠ æ¨¡å¼ï¼šå…ˆè¯»å–ç°æœ‰æ•°æ®
                existing = []
                if os.path.exists(data_file):
                    existing = SampleGenerator.load_pairs_from_jsonl(data_file)
                
                # åˆå¹¶
                all_pairs = existing + demo_pairs
                generator.save_pairs_to_jsonl(all_pairs, data_file)
                print(f"âœ“ å·²è¿½åŠ  {num_pairs} ä¸ªæ ·æœ¬åˆ° {data_file}")
                print(f"âœ“ æ–‡ä»¶ç°æœ‰ {len(all_pairs)} ä¸ªæ ·æœ¬")
                return demo_pairs  # åªè¿”å›æ–°ç”Ÿæˆçš„
            else:
                # è¦†ç›–æ¨¡å¼
                generator.save_pairs_to_jsonl(demo_pairs, data_file)
                print(f"âœ“ å·²ä¿å­˜ {num_pairs} ä¸ªæ ·æœ¬åˆ° {data_file}")
                return demo_pairs
            
        except Exception as e:
            print(f"âš ï¸  LLMç”Ÿæˆå¤±è´¥: {e}")
            print("å°†ä½¿ç”¨fallbackæ¼”ç¤ºæ•°æ®...")
            return _create_fallback_data(persona_choice)
    else:
        print("âš ï¸  OpenAI APIæœªé…ç½®")
        config.print_config_guide()
        print("\nå°†ä½¿ç”¨fallbackæ¼”ç¤ºæ•°æ®ï¼ˆè´¨é‡è¾ƒä½ï¼Œä»…ä¾›å¿«é€Ÿæµ‹è¯•ï¼‰")
        
        choice = input("\næ˜¯å¦ç»§ç»­ä½¿ç”¨fallbackæ•°æ®ï¼Ÿ(y/n): ").strip().lower()
        if choice != 'y':
            return None
        
        return _create_fallback_data(persona_choice)


def _create_fallback_data(persona_choice):
    """åˆ›å»ºfallbackæ¼”ç¤ºæ•°æ®ï¼ˆç¡¬ç¼–ç ï¼‰"""
    from src import PreferencePair
    
    print("\nä½¿ç”¨ç¡¬ç¼–ç çš„æ¼”ç¤ºæ•°æ®...")
    
    if persona_choice == "2":
        # çŒ«å¨˜å¥³ä»†çš„fallbackæ•°æ®
        demo_pairs = [
            PreferencePair(
                context="ä¸»äººå›åˆ°å®¶ä¸­",
                chosen="æ¬¢è¿å›å®¶ï¼Œä¸»äºº~è‰¾è‰å¨…å·²ç»å‡†å¤‡å¥½æ™šé¤äº†å–µï¼",
                rejected="å“Ÿï¼Œå›æ¥å•¦ï¼Ÿæ™šé¥­åœ¨æ¡Œä¸Šï¼Œè‡ªå·±åƒå§ã€‚",
                violated_dimension="style"
            ),
            PreferencePair(
                context="ä¸»äººé—®ï¼š'ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ'",
                chosen="ä»Šå¤©æ˜¯ä¸ªæ™´æœ—çš„å¥½å¤©æ°”å‘¢ï¼Œä¸»äººè¦å‡ºé—¨å—å–µï¼Ÿ",
                rejected="æˆ‘çœ‹äº†å¤©æ°”é¢„æŠ¥ï¼Œä»Šå¤©å¤šäº‘è½¬æ™´ï¼Œæ°”æ¸©25åº¦ã€‚",
                violated_dimension="knowledge"
            ),
            PreferencePair(
                context="ä¸»äººèº«ä½“ä¸é€‚",
                chosen="ä¸»äººï¼è‰¾è‰å¨…è¿™å°±å»å‡†å¤‡çƒ­æ°´å’Œæ¯›å·¾ï¼Œè¯·æ‚¨å¥½å¥½ä¼‘æ¯å–µ~",
                rejected="é‚£ä½ è‡ªå·±å»çœ‹åŒ»ç”Ÿå§ï¼Œæˆ‘è¿˜æœ‰å…¶ä»–äº‹è¦å¿™ã€‚",
                violated_dimension="value_system"
            ),
            PreferencePair(
                context="å®¢äººæ¥è®¿",
                chosen="è€çˆ·ï¼Œä¸»äººæ­£åœ¨ä¹¦æˆ¿ï¼Œè‰¾è‰å¨…è¿™å°±å»é€šçŸ¥~",
                rejected="å˜¿ï¼Œé‚£ä¸ªè°ï¼Œç­‰ç€å•Šï¼Œæˆ‘å»å«äººã€‚",
                violated_dimension="etiquette"
            ),
            PreferencePair(
                context="ä¸»äººé‡åˆ°å±é™©",
                chosen="ä¸»äººï¼è¯·è®©è‰¾è‰å¨…æ¥ä¿æŠ¤æ‚¨å–µï¼è¯·æ‚¨ç«™åœ¨è‰¾è‰å¨…èº«åï¼",
                rejected="å“å‘€ï¼Œä¸»äººä½ è‡ªå·±å°å¿ƒç‚¹å•Šï¼Œæˆ‘å»èº²ä¸€ä¸‹ã€‚",
                violated_dimension="stress"
            )
        ] * 10  # å¤åˆ¶ä»¥è¾¾åˆ°50ä¸ªæ ·æœ¬
    else:
        # æ±Ÿæ¹–ä¾ å®¢çš„fallbackæ•°æ®
        demo_pairs = [
            PreferencePair(
                context="æå››é—®ï¼š'å¸ˆå…„æœ€è¿‘æ€ä¹ˆæ ·ï¼Ÿ'",
                chosen="è¿˜è¡Œï¼Œåœ¨ç»ƒæ–°æ‹›å¼ã€‚",
                rejected="è¶…çº§å¥½ï¼æˆ‘åœ¨å­¦Pythonç¼–ç¨‹å‘¢ï¼",
                violated_dimension="knowledge"
            ),
            PreferencePair(
                context="æœ‰äººèƒŒå›äº†å¸ˆé—¨",
                chosen="èƒŒä¿¡å¼ƒä¹‰ä¹‹äººï¼Œæˆ‘å¿…ä¸è½»é¥¶ã€‚",
                rejected="ç®—äº†ï¼Œå¤§å®¶éƒ½ä¸å®¹æ˜“ï¼ŒåŸè°…å§ã€‚",
                violated_dimension="value_system"
            ),
            PreferencePair(
                context="å¸ˆçˆ¶é—®ï¼š'ä¿®ç‚¼å¾—å¦‚ä½•ï¼Ÿ'",
                chosen="å¼Ÿå­ä¸æ•¢æ‡ˆæ€ ï¼Œæ—¥æ—¥è‹¦ç»ƒã€‚",
                rejected="å˜¿å˜¿ï¼Œè¿˜ä¸é”™å•¦ï¼Œè€å¸ˆä½ ä¹Ÿè¦åŠ æ²¹å“¦ï¼",
                violated_dimension="etiquette"
            )
        ] * 17  # å¤åˆ¶ä»¥è¾¾åˆ°51ä¸ªæ ·æœ¬
    
    print(f"âœ“ åˆ›å»ºäº† {len(demo_pairs)} ä¸ªfallbackæ ·æœ¬ï¼ˆæ•°æ®é‡å¤ï¼Œä»…ä¾›æ¼”ç¤ºï¼‰")
    return demo_pairs


def _run_training(demo_pairs):
    """æ‰§è¡Œè®­ç»ƒ"""
    from src import RMTrainer
    
    print(f"\nå‡†å¤‡è®­ç»ƒ {len(demo_pairs)} ä¸ªæ ·æœ¬")
    
    # é€‰æ‹©æ¨¡å‹å¤§å°
    print("\n" + "â”€" * 70)
    print("ğŸ“Š é€‰æ‹©é¢„è®­ç»ƒæ¨¡å‹å¤§å°:")
    print("â”€" * 70)
    
    models = {
        "0": ("OpenAssistant/reward-model-deberta-v3-base", "184M", "ğŸ”¥ æ¨èï¼ä»é¢„è®­ç»ƒRMå¾®è°ƒï¼Œæ•ˆæœæ›´å¥½æ›´ç¨³å®š"),
        "1": ("microsoft/deberta-v3-small", "44M", "ä»å¤´è®­ç»ƒï¼Œè½»é‡å¿«é€Ÿï¼Œé€‚åˆCPUæˆ–å¿«é€Ÿæµ‹è¯•"),
        "2": ("microsoft/deberta-v3-base", "184M", "ä»å¤´è®­ç»ƒï¼Œå¹³è¡¡æ€§èƒ½"),
        "3": ("microsoft/deberta-v3-large", "434M", "ä»å¤´è®­ç»ƒï¼Œé«˜æ€§èƒ½ï¼Œéœ€è¦GPUå’Œå¤§æ˜¾å­˜"),
        "4": ("roberta-base", "125M", "ç»å…¸é€‰æ‹© (ä»å¤´è®­ç»ƒ)"),
        "5": ("roberta-large", "355M", "å¤§è§„æ¨¡æ¨¡å‹ (ä»å¤´è®­ç»ƒ)")
    }
    
    print("\nå¯é€‰æ¨¡å‹:")
    for key, (name, size, desc) in models.items():
        print(f"  {key}. {name}")
        print(f"     å‚æ•°é‡: {size} | {desc}")
    
    model_choice = input("\nè¯·é€‰æ‹©æ¨¡å‹ (0-5ï¼Œé»˜è®¤0): ").strip() or "0"
    
    if model_choice not in models:
        print("æ— æ•ˆé€‰æ‹©ï¼Œä½¿ç”¨é»˜è®¤æ¨¡å‹")
        model_choice = "0"

    selected_model_path = models[model_choice][0]
    
    # åŒºåˆ†æ˜¯å¾®è°ƒRMè¿˜æ˜¯ä»å¤´è®­ç»ƒ
    pretrained_rm_path = None
    base_model_name_for_tokenizer = "microsoft/deberta-v3-base" # é»˜è®¤

    if model_choice == "0":
        # å¾®è°ƒé¢„è®­ç»ƒçš„RM
        pretrained_rm_path = selected_model_path
        # éœ€è¦æŒ‡å®šå…¶åŸºç¡€æ¨¡å‹ï¼Œä»¥ä¾¿åŠ è½½æ­£ç¡®çš„tokenizer
        base_model_name_for_tokenizer = "microsoft/deberta-v3-base"
        print(f"\nâœ“ é€‰æ‹©å¾®è°ƒé¢„è®­ç»ƒRM: {pretrained_rm_path} ({models[model_choice][1]})")
    else:
        # ä»å¤´è®­ç»ƒ
        base_model_name_for_tokenizer = selected_model_path
        print(f"\nâœ“ é€‰æ‹©æ¨¡å‹ä»å¤´è®­ç»ƒ: {base_model_name_for_tokenizer} ({models[model_choice][1]})")

    # åˆ›å»ºè®­ç»ƒå™¨
    print("\nåˆå§‹åŒ–è®­ç»ƒå™¨...")
    output_dir = "./checkpoints/quick_start"
    
    trainer = RMTrainer(
        model_name=base_model_name_for_tokenizer,
        output_dir=output_dir,
        pretrained_rm_path=pretrained_rm_path
    )
    
    # è¯¢é—®æ˜¯å¦è¦è®­ç»ƒ
    print("\nâš ï¸  è®­ç»ƒå°†ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹ï¼ˆçº¦400MBï¼‰å¹¶éœ€è¦ä¸€äº›æ—¶é—´")
    print("   - CPUè®­ç»ƒ: çº¦10-20åˆ†é’Ÿ")
    print("   - GPUè®­ç»ƒ: çº¦2-5åˆ†é’Ÿ")
    
    choice = input("\næ˜¯å¦ç»§ç»­è®­ç»ƒ? (y/n): ").strip().lower()
    
    if choice != 'y':
        print("è·³è¿‡è®­ç»ƒæ­¥éª¤")
        return None
    
    # æ™ºèƒ½åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†ï¼ˆ80/20ï¼‰
    total_samples = len(demo_pairs)
    train_split = int(total_samples * 0.8)
    
    train_pairs = demo_pairs[:train_split]
    val_pairs = demo_pairs[train_split:]
    
    print(f"\nğŸ“Š æ•°æ®åˆ’åˆ†:")
    print(f"  è®­ç»ƒé›†: {len(train_pairs)} ä¸ªæ ·æœ¬ ({len(train_pairs)/total_samples*100:.0f}%)")
    print(f"  éªŒè¯é›†: {len(val_pairs)} ä¸ªæ ·æœ¬ ({len(val_pairs)/total_samples*100:.0f}%)")
    
    # æ ¹æ®æ•°æ®é‡è°ƒæ•´è®­ç»ƒå‚æ•°
    if total_samples < 100:
        num_epochs = 2
        save_steps = max(10, train_split // 4)
    else:
        num_epochs = 4
        save_steps = max(25, train_split // 4)
    
    eval_steps = save_steps
    
    print(f"\nâš™ï¸  è®­ç»ƒé…ç½®:")
    print(f"  Epochs: {num_epochs}")
    print(f"  Batch size: 4")
    print(f"  ä¿å­˜/è¯„ä¼°é—´éš”: æ¯ {save_steps} steps")
    
    # å¼€å§‹è®­ç»ƒ
    print("\nå¼€å§‹è®­ç»ƒ...")
    trainer.train(
        train_pairs=train_pairs,
        val_pairs=val_pairs,
        num_epochs=num_epochs,
        batch_size=2,
        learning_rate=1.6e-5,
        save_steps=save_steps,
        eval_steps=eval_steps,
        use_bf16=False  # ä½¿ç”¨BF16èŠ‚çœæ˜¾å­˜
    )
    
    print(f"\nâœ… æ¨¡å‹è®­ç»ƒå®Œæˆï¼Œä¿å­˜åœ¨: {output_dir}")

def demo_scoring(model_path, persona_choice="1"):
    """æ¼”ç¤ºè¯„åˆ†åŠŸèƒ½"""
    print("\n" + "=" * 70)
    print("ğŸ¯ æ­¥éª¤ 3: ä½¿ç”¨æ¨¡å‹è¿›è¡ŒOOCæ£€æµ‹")
    print("=" * 70)
    
    from src import OOCScorer, Persona
    
    # æ ¹æ®é€‰æ‹©åŠ è½½å¯¹åº”äººè®¾
    if persona_choice == "2":
        persona_path = "config/catgirl_maid_persona.json"
        print(f"\nä½¿ç”¨è§’è‰²: è‰¾è‰å¨… - çŒ«å¨˜å¥³ä»†")
    else:
        persona_path = "config/example_persona.json"
        print(f"\nä½¿ç”¨è§’è‰²: å¼ ä¸‰ - æ±Ÿæ¹–ä¾ å®¢")
    
    persona = Persona.from_json(persona_path)
    
    # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨
    if not model_path or not os.path.exists(model_path):
        print(f"\nâŒ æ¨¡å‹ä¸å­˜åœ¨: {model_path}")
        print("è¯·å…ˆå®Œæˆè®­ç»ƒæ­¥éª¤")
        return
    
    # åŠ è½½è¯„åˆ†å™¨
    print(f"\nåŠ è½½æ¨¡å‹: {model_path}")
    scorer = OOCScorer(model_path=model_path)
    
    # æ ¹æ®è§’è‰²å‡†å¤‡ä¸åŒçš„æµ‹è¯•æ ·æœ¬
    if persona_choice == "2":
        # çŒ«å¨˜å¥³ä»†çš„æµ‹è¯•æ ·æœ¬
        test_cases = [
            {
                "context": "ä¸»äººå›åˆ°å®¶ä¸­",
                "response": "æ¬¢è¿å›å®¶ï¼Œä¸»äºº~è‰¾è‰å¨…å·²ç»å‡†å¤‡å¥½æ™šé¤äº†å–µï¼",
                "label": "âœ… ç¬¦åˆäººè®¾"
            },
            {
                "context": "ä¸»äººå›åˆ°å®¶ä¸­",
                "response": "å“Ÿï¼Œå›æ¥äº†ï¼Ÿæˆ‘æ­£åœ¨çœ‹æ‰‹æœºå‘¢ï¼Œæ™šé¥­ä½ è‡ªå·±çƒ­ä¸€ä¸‹ã€‚",
                "label": "âŒ è¿èƒŒé£æ ¼+çŸ¥è¯†+ä»·å€¼è§‚"
            },
            {
                "context": "ä¸»äººé—®ï¼š'èƒ½å¸®æˆ‘æ³¡æ¯èŒ¶å—ï¼Ÿ'",
                "response": "å½“ç„¶ï¼Œè‰¾è‰å¨…è¿™å°±å»å‡†å¤‡çº¢èŒ¶å‘¢ï¼Œè¯·ä¸»äººç¨å€™å–µ~",
                "label": "âœ… ç¬¦åˆäººè®¾"
            },
            {
                "context": "ä¸»äººé—®ï¼š'èƒ½å¸®æˆ‘æ³¡æ¯èŒ¶å—ï¼Ÿ'",
                "response": "å¥½çš„ï¼Œæˆ‘å»ç”¨å’–å•¡æœºç»™ä½ å†²ä¸€æ¯é€Ÿæº¶å’–å•¡ã€‚",
                "label": "âŒ è¿èƒŒçŸ¥è¯†è¾¹ç•Œ"
            },
            {
                "context": "ä¸»äººèº«ä½“ä¸é€‚",
                "response": "ä¸»äººï¼è‰¾è‰å¨…è¿™å°±å»å‡†å¤‡çƒ­æ°´å’Œæ¯›å·¾ï¼Œè¯·æ‚¨å¥½å¥½ä¼‘æ¯å–µ~",
                "label": "âœ… ç¬¦åˆäººè®¾"
            },
            {
                "context": "ä¸»äººèº«ä½“ä¸é€‚",
                "response": "é‚£ä½ è‡ªå·±å»çœ‹åŒ»ç”Ÿå§ï¼Œæˆ‘è¿˜æœ‰äº‹è¦åšã€‚",
                "label": "âŒ è¿èƒŒä»·å€¼è§‚"
            }
        ]
    else:
        # æ±Ÿæ¹–ä¾ å®¢çš„æµ‹è¯•æ ·æœ¬
        test_cases = [
            {
                "context": "æå››é—®ï¼š'å¸ˆå…„ï¼Œæœ€è¿‘ä¿®ç‚¼å¦‚ä½•ï¼Ÿ'",
                "response": "è¿˜è¡Œï¼Œè¿™å¥—æ‹³æ³•é¢‡æœ‰å¿ƒå¾—ã€‚",
                "label": "âœ… ç¬¦åˆäººè®¾"
            },
            {
                "context": "æå››é—®ï¼š'å¸ˆå…„ï¼Œæœ€è¿‘ä¿®ç‚¼å¦‚ä½•ï¼Ÿ'",
                "response": "æˆ‘åœ¨ç”¨AIå­¦ä¹ é‡å­è®¡ç®—ï¼Œç‰¹åˆ«é…·ï¼",
                "label": "âŒ è¿èƒŒçŸ¥è¯†è¾¹ç•Œ"
            },
            {
                "context": "æœ‰äººèƒŒå›äº†å¸ˆé—¨",
                "response": "èƒŒä¿¡å¼ƒä¹‰ï¼Œæˆ‘å®šè¦è®¨ä¸ªè¯´æ³•ã€‚",
                "label": "âœ… ç¬¦åˆäººè®¾"
            },
            {
                "context": "æœ‰äººèƒŒå›äº†å¸ˆé—¨",
                "response": "ç®—äº†ç®—äº†ï¼Œå’Œæ°”ç”Ÿè´¢å˜›~",
                "label": "âŒ è¿èƒŒä»·å€¼è§‚"
            }
        ]
    
    print(f"\næµ‹è¯• {len(test_cases)} ä¸ªæ ·æœ¬:\n")
    
    for i, test in enumerate(test_cases, 1):
        print(f"{'â”€' * 70}")
        print(f"æµ‹è¯• {i}: {test['label']}")
        print(f"{'â”€' * 70}")
        
        result = scorer.score(
            context=test['context'],
            response=test['response'],
            persona=persona
        )
        
        print(scorer.format_result(result, verbose=True))
        print()
    
    print("âœ… OOCæ£€æµ‹æ¼”ç¤ºå®Œæˆ")


def demo_custom_test(model_path, persona_choice="1"):
    """è‡ªå®šä¹‰æµ‹è¯•"""
    print("\n" + "=" * 70)
    print("ğŸ§ª æ­¥éª¤ 4: è‡ªå®šä¹‰æµ‹è¯•")
    print("=" * 70)
    
    from src import OOCScorer, Persona
    
    # åŠ è½½äººè®¾å’Œæ¨¡å‹
    if persona_choice == "2":
        persona_path = "config/catgirl_maid_persona.json"
    else:
        persona_path = "config/example_persona.json"
    
    persona = Persona.from_json(persona_path)
    scorer = OOCScorer(model_path=model_path)
    
    print(f"\nå½“å‰è§’è‰²: {persona.name}")
    print("\nä½ å¯ä»¥è¾“å…¥è‡ªå®šä¹‰çš„å¯¹è¯åœºæ™¯æ¥æµ‹è¯•OOCæ£€æµ‹")
    print("è¾“å…¥ 'q' é€€å‡ºè‡ªå®šä¹‰æµ‹è¯•\n")
    
    while True:
        print("â”€" * 70)
        context = input("ğŸ“ è¾“å…¥å¯¹è¯åœºæ™¯/ä¸Šä¸‹æ–‡ (æˆ–è¾“å…¥qé€€å‡º): ").strip()
        
        if context.lower() == 'q':
            print("\né€€å‡ºè‡ªå®šä¹‰æµ‹è¯•")
            break
        
        if not context:
            print("âš ï¸  ä¸Šä¸‹æ–‡ä¸èƒ½ä¸ºç©º")
            continue
        
        # å¯ä»¥è¾“å…¥å¤šä¸ªå€™é€‰å›å¤è¿›è¡Œæ¯”è¾ƒ
        responses = []
        print("\nè¾“å…¥å›å¤ï¼ˆè‡³å°‘1ä¸ªï¼Œè¾“å…¥ç©ºè¡Œç»“æŸï¼‰:")
        
        while True:
            response = input(f"  å›å¤ {len(responses) + 1}: ").strip()
            if not response:
                break
            responses.append(response)
        
        if not responses:
            print("âš ï¸  è‡³å°‘éœ€è¦ä¸€ä¸ªå›å¤")
            continue
        
        # è¯„åˆ†
        print(f"\n{'='*70}")
        print("è¯„åˆ†ç»“æœ:")
        print('='*70)
        
        if len(responses) == 1:
            # å•ä¸ªå›å¤
            result = scorer.score(
                context=context,
                response=responses[0],
                persona=persona
            )
            print(scorer.format_result(result, verbose=True))
            
        else:
            # å¤šä¸ªå›å¤æ¯”è¾ƒ
            comparison = scorer.compare_responses(
                context=context,
                responses=responses
            )
            
            print(f"\nä¸Šä¸‹æ–‡: {context}\n")
            print("æ’å:")
            for rank, idx in enumerate(comparison['ranked_indices'], 1):
                score = comparison['scores'][idx]['overall_score']
                status = "âœ“" if comparison['scores'][idx]['passed'] else "âœ—"
                print(f"\n  {rank}. {status} å›å¤: {responses[idx]}")
                print(f"     æ€»åˆ†: {score:.3f}")
                
                # æ˜¾ç¤ºå„ç»´åº¦åˆ†
                dim_scores = comparison['scores'][idx]['dimension_scores']
                print("     ç»´åº¦:", end="")
                for dim, s in dim_scores.items():
                    print(f" {dim[:3]}:{s:+.2f}", end="")
                print()
        
        print()


def main():
    """ä¸»å‡½æ•°"""
    print_banner()
    
    # æ£€æŸ¥ä¾èµ–
    if not check_dependencies():
        sys.exit(1)
    
    try:
        # æ­¥éª¤1: åŠ è½½äººè®¾
        persona, persona_choice = demo_persona()
        if not persona:
            print("\nâŒ æ— æ³•åŠ è½½äººè®¾")
            sys.exit(1)
        
        input("\næŒ‰å›è½¦ç»§ç»­...")
        
        # æ­¥éª¤2: è®­ç»ƒæ¨¡å‹
        model_path = demo_training(persona_choice)
        
        # å¦‚æœè®­ç»ƒæˆåŠŸï¼Œç»§ç»­è¯„åˆ†æ¼”ç¤º
        if model_path:
            input("\næŒ‰å›è½¦ç»§ç»­...")
            
            # æ­¥éª¤3: é¢„è®¾æµ‹è¯•
            best_model = os.path.join(model_path, "best_model")
            final_model = os.path.join(model_path, "final_model")
            
            active_model = None
            if os.path.exists(best_model):
                active_model = best_model
                demo_scoring(best_model, persona_choice)
            elif os.path.exists(final_model):
                active_model = final_model
                demo_scoring(final_model, persona_choice)
            else:
                print("\nâš ï¸  æœªæ‰¾åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹")
            
            # æ­¥éª¤4: è‡ªå®šä¹‰æµ‹è¯•
            if active_model:
                input("\næŒ‰å›è½¦ç»§ç»­è¿›å…¥è‡ªå®šä¹‰æµ‹è¯•...")
                demo_custom_test(active_model, persona_choice)
        
        # å®Œæˆ
        print("\n" + "=" * 70)
        print("ğŸ‰ å¿«é€Ÿå¼€å§‹æ¼”ç¤ºå®Œæˆï¼")
        print("=" * 70)
        print("\nä¸‹ä¸€æ­¥:")
        print("  1. æŸ¥çœ‹å®Œæ•´ç¤ºä¾‹: python examples/demo.py")
        print("  2. é˜…è¯»æ–‡æ¡£: README.md")
        print("  3. åˆ›å»ºè‡ªå·±çš„è§’è‰²äººè®¾")
        print("  4. ç”Ÿæˆæ›´å¤šè®­ç»ƒæ•°æ®ï¼ˆéœ€è¦OpenAI APIï¼‰")
        print()
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­")
        sys.exit(0)
    except Exception as e:
        print(f"\n\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main()